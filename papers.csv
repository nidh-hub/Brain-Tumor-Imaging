Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier,include title,include abstract,exclude,accept contents,Research question answers
Automated Brain Metastases Detection Framework for T1-Weighted Contrast-Enhanced 3D MRI,E. Dikici; J. L. Ryu; M. Demirer; M. Bigelow; R. D. White; W. Slone; B. S. Erdal; L. M. Prevedello,"Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA; Department of Radiology, Perelman School of Medicine, The University of Pennsylvania, Philadelphia, PA, USA; Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA; Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA; Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA; Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA; Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA; Department of Radiology, The Ohio State University College of Medicine, Columbus, OH, USA",IEEE Journal of Biomedical and Health Informatics,07-Oct-20,2020,24,10,2883,2893,"Brain Metastases (BM) complicate 20-40% of cancer cases. BM lesions can present as punctate (1 mm) foci, requiring high-precision Magnetic Resonance Imaging (MRI) in order to prevent inadequate or delayed BM treatment. However, BM lesion detection remains challenging partly due to their structural similarities to normal structures (e.g., vasculature). We propose a BM-detection framework using a single-sequence gadolinium-enhanced T1-weighted 3D MRI dataset. The framework focuses on the detection of smaller (<; 15 mm) BM lesions and consists of: (1) candidate-selection stage, using Laplacian of Gaussian approach for highlighting parts of an MRI volume holding higher BM occurrence probabilities, and (2) detection stage that iteratively processes cropped region-of-interest volumes centered by candidates using a custom-built 3D convolutional neural network (“CropNet”). Data is augmented extensively during training via a pipeline consisting of random ga mma correction and elastic deformation stages; the framework thereby maintains its invariance for a plausible range of BM shape and intensity representations. This approach is tested using five-fold cross-validation on 217 datasets from 158 patients, with training and testing groups randomized per patient to eliminate learning bias. The BM database included lesions with a mean diameter of ~5.4 mm and a mean volume of ~160 mm3. For 90% BM-detection sensitivity, the framework produced on average 9.12 false-positive BM detections per patient (standard deviation of 3.49); for 85% sensitivity, the average number of false-positives declined to 5.85. Comparative analysis showed that the framework produces comparable BM-detection accuracy with the state-of-art approaches validated for significantly larger lesions.",2168-2208,,10.1109/JBHI.2020.2982103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044379,Magnetic resonance imaging;brain metastases;convolutional neural networks;deep learning;scale-space representations;computer-aided detection;medical image analysis,Magnetic resonance imaging;Lesions;Three-dimensional displays;Sensitivity;Training;Strain;Informatics,biomedical MRI;brain;cancer;convolutional neural nets;elastic deformation;image enhancement;image segmentation;medical image processing;tumours,automated brain metastases detection framework;T1-weighted contrast-enhanced 3D MRI;high-precision Magnetic Resonance Imaging;inadequate BM treatment;delayed BM treatment;BM lesion detection;structural similarities;BM-detection framework;single-sequence gadolinium-enhanced T1-weighted 3D;Gaussian approach;MRI volume;region-of-interest volumes;custom-built 3D convolutional neural network;elastic deformation stages;BM database;BM-detection sensitivity;false-positive BM detections,,,,53,CCBY,23-Mar-20,,,IEEE,IEEE Journals,yes,yes,,yes ,Paper proposes BM-detection framework using a single-sequence gadolinium-enhanced T1-weighted 3D MRI dataset
BAT Algorithm With fuzzy C-Ordered Means (BAFCOM) Clustering Segmentation and Enhanced Capsule Networks (ECN) for Brain Cancer MRI Images Classification,A. M. Alhassan; W. M. N. W. Zainon,"School of Computer Science, Universiti Sains Malaysia, George Town, Malaysia; School of Computer Science, Universiti Sains Malaysia, George Town, Malaysia",IEEE Access,18-Nov-20,2020,8,,201741,201751,"Cancer is a second foremost life-threatening disease next to cardiovascular diseases. In particular, brain cancer holds the least rate of survival than all other cancer types. The categorization of a brain tumor depends upon the various factors such as texture, shape and location. The medical experts have preferred the appropriate treatment to the patients, based on the accurate identification of tumor type. The process of segmenting the Magnetic Resonance Imaging (MRI) has high complicacy during the analysis of brain tumor, owing to its variable shape, location, size, and texture. The physicians and radiologists can easily detect and categorize the tumors if there exists a system by combining Computer Assisted Diagnosis (CAD) as well as Artificial Intelligence (AI). An approach of automated segmentation has proposed in this paper, which enables the segmentation of tumor out of MRI images, besides enhances the efficiency of segmentation and classification. The initial functions of this approach include preprocessing and segmentation processes for segmenting tumor or tissue of benign and malignant by expanding a range of data and clustering. A modern learning-based approach has suggested in this study, in order to process the automated segmentation in multimodal MRI images to identify brain tumor, hence the clustering algorithm of Bat Algorithm with Fuzzy C-Ordered Means (BAFCOM) has recommended segmenting the tumor. The Bat Algorithm calculates the initial centroids and distance within the pixels in the clustering algorithm of BAFCOM, which also acquires the tumor through determining the distance among tumor Region of Interest (RoI) and non-tumor RoI. Afterwards, the MRI image has analyzed by the Enhanced Capsule Networks (ECN) method to categorize it as normal and brain tumor. Ultimately, the algorithm of ECN has assessed the performance of proposed approach by distinguishing the two categories of the tumor over MRI images, besides the suggested ECN classifier has assessed by the measurement factors of accuracy, precision, recall, and F1-score. In addition, the genetic algorithm has applied to process the automatic tumor stage classification, which in turn classification accuracy enhanced.",2169-3536,,10.1109/ACCESS.2020.3035803,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247957,Machine learning;enhanced capsule networks (ECN);brain tumor;bat algorithm with fuzzy c-ordered means (BAFCOM);magnetic resonance imaging (MRI) images,Tumors;Clustering algorithms;Image segmentation;Magnetic resonance imaging;Cancer;Shape;Brain modeling,biomedical MRI;brain;cancer;fuzzy set theory;genetic algorithms;image classification;image segmentation;image texture;learning (artificial intelligence);medical image processing;neural nets;pattern clustering;tumours,BAFCOM;ECN;brain cancer MRI images classification;brain tumor;magnetic resonance imaging;automated segmentation;multimodal MRI images;automatic tumor stage classification;nontumor RoI;tumor region-of-interest;enhanced capsule networks;computer assisted diagnosis;artificial intelligence;learning-based approach;F1-score;genetic algorithm;Bat-algorithm-with-fuzzy-C-ordered-means clustering segmentation,,,,38,CCBY,04-Nov-20,,,IEEE,IEEE Journals,yes,yes,,yes ,Automated segmentation of tumour out of MRI images to enhance  the efficiency of segmentation and classification
Brain Tumor Detection Based on Multimodal Information Fusion and Convolutional Neural Network,M. Li; L. Kuang; S. Xu; Z. Sha,"Department of Nuclear Medicine, Rizhao People’s Hospital, Rizhao, China; Department of Radiology, Rizhao People’s Hospital, Rizhao, China; Department of Radiology, Rizhao People’s Hospital, Rizhao, China; Department of Radiology, Rizhao People’s Hospital, Rizhao, China",IEEE Access,23-Dec-19,2019,7,,180134,180146,"Aiming at the problem of low accuracy of traditional brain tumor detection, in this paper, a combination of multimodal information fusion and convolution neural network detection method of brain tumors, we call it a Multi-CNNs. First, this paper uses the extension of the 2D-CNNs to multimodal 3D-CNNs, and can obtain brain lesions under different modal characteristics of three-dimensional space. It can solve the 2D-CNNs raw input requires large neighborhood of faults, at the same time better to extract the modal of the differences between information. Then the real normalization layer is added between the convolution layers and pooling layer to improve the convergence speeds of the network and alleviate the problem of overfitting. In the end, the loss function was improved, and the weighted loss function was used to enhance the feature learning of the lesion area. The experimental results showed that the brain tumor detection method proposed in this paper could effectively locate tumor lesions, and better results were obtained in correlation coefficient, sensitivity, and specificity. Compared with two-dimensional detection network and single mode brain tumor detection methods, the detection accuracy is significantly improved.",2169-3536,,10.1109/ACCESS.2019.2958370,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928592,Multimodal;fusion;convolutional neural network;brain tumor,Magnetic resonance imaging;Brain modeling;Three-dimensional displays;Convolutional neural networks;Lesions;Manuals,biomedical MRI;brain;convolutional neural nets;image fusion;learning (artificial intelligence);medical image processing;tumours,three-dimensional space;2D-CNNs raw input;weighted loss function;lesion area;brain tumor detection method;tumor lesions;two-dimensional detection network;single mode brain tumor detection methods;detection accuracy;multimodal information fusion;convolutional neural network;convolution neural network detection method;brain tumors;MultiCNNs;brain lesions,,1,,39,CCBY,09-Dec-19,,,IEEE,IEEE Journals,yes,yes,,yes ,A combination of CNN tumour detection method and multimodal information fusion
A Deep Learning Model Based on Concatenation Approach for the Diagnosis of Brain Tumor,N. Noreen; S. Palaniappan; A. Qayyum; I. Ahmad; M. Imran; M. Shoaib,"Department of Information Technology, School of Science and Engineering, Malaysia University of Science and Technology, Petaling Jaya, Malaysia; Department of Information Technology, School of Science and Engineering, Malaysia University of Science and Technology, Petaling Jaya, Malaysia; ImViA Laboratory, University of Bourgogne Franche-Comté, Dijon, France; Department of Information Technology, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",IEEE Access,26-Mar-20,2020,8,,55135,55144,"Brain tumor is a deadly disease and its classification is a challenging task for radiologists because of the heterogeneous nature of the tumor cells. Recently, computer-aided diagnosis-based systems have promised, as an assistive technology, to diagnose the brain tumor, through magnetic resonance imaging (MRI). In recent applications of pre-trained models, normally features are extracted from bottom layers which are different from natural images to medical images. To overcome this problem, this study proposes a method of multi-level features extraction and concatenation for early diagnosis of brain tumor. Two pre-trained deep learning models i.e. Inception-v3 and DensNet201 make this model valid. With the help of these two models, two different scenarios of brain tumor detection and its classification were evaluated. First, the features from different Inception modules were extracted from pre-trained Inception-v3 model and concatenated these features for brain tumor classification. Then, these features were passed to softmax classifier to classify the brain tumor. Second, pre-trained DensNet201 was used to extract features from various DensNet blocks. Then, these features were concatenated and passed to softmax classifier to classify the brain tumor. Both scenarios were evaluated with the help of three-class brain tumor dataset that is available publicly. The proposed method produced 99.34 %, and 99.51% testing accuracies respectively with Inception-v3 and DensNet201 on testing samples and achieved highest performance in the detection of brain tumor. As results indicated, the proposed method based on features concatenation using pre-trained models outperformed as compared to existing state-of-the-art deep learning and machine learning based methods for brain tumor classification.",2169-3536,,10.1109/ACCESS.2020.2978629,King Abdulaziz University; DSR for technical and financial support; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025004,Deep learning;magnetic resonance imaging;brain tumor classification;pre-trained model;dataset,Tumors;Feature extraction;Machine learning;Brain modeling;Magnetic resonance imaging;Biomedical imaging;Diseases,biomedical MRI;brain;diseases;feature extraction;image classification;learning (artificial intelligence);medical image processing;neural nets;tumours,deep learning models;brain tumor detection;brain tumor classification;pre-trained DensNet201;three-class brain tumor dataset;tumor cells;concatenation approach;brain tumor diagnosis;disease;computer-aided diagnosis-based systems;magnetic resonance imaging;MRI;feature extraction;Inception-v3 model;Inception modules;softmax classifier,,9,,27,CCBY,05-Mar-20,,,IEEE,IEEE Journals,yes,yes,,yes,Paper discusses methods of multi-level features extraction and concatenation for early diagnosis of brain tumor
A Noninvasive System for the Automatic Detection of Gliomas Based on Hybrid Features and PSO-KSVM,G. Song; Z. Huang; Y. Zhao; X. Zhao; Y. Liu; M. Bao; J. Han; P. Li,"State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Shenjing Hospital, China Medical University, Shenyang, China; Shenjing Hospital, China Medical University, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China",IEEE Access,08-Feb-19,2019,7,,13842,13855,"Due to their location, malignant brain tumors are one of humanity's greatest killers, among these tumors, gliomas are the most common. The early detection of gliomas can contribute to the design of proper treatment schemes and, thus, improve the survival rate of patients. However, it is a challenging task to detect the gliomas within the complex structure of the brain. The conventional artificial diagnosis is time-consuming and relies on the clinical experience of radiologists. To detect gliomas more efficiently, this paper proposes a noninvasive automatic diagnosis system for gliomas based on the machine learning methods. First, image standardization, including size normalization and background removal, is applied to produce standard images; then, the modified dynamic histogram equalization is implemented to enhance the low-contrast standard brain images, and skull removal based on outlier detection is presented. Furthermore, hybrid features, including gray-level co-occurrence matrix, pyramid histogram of the oriented gradient, modified completed local binary pattern, and intensity-based features are extracted together from the enhanced images, and their dimensions are reduced by principal component analysis. Kernel support vector machine (KSVM) combined with the particle swarm optimization is eventually adopted to train classifiers; in this paper, brain magnetic resonance imaging images are labeled with normal, glioma, and other. The experimental results show that the accuracy, sensitivity, and specificity of the proposed method can reach 98.36%, 99.17%, and 97.83%, respectively, which indicates that the proposed method performs better than many current systems.",2169-3536,,10.1109/ACCESS.2019.2894435,National Natural Science Foundation of China; National Key R&D Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630960,Modified CLBP;PSO-KSVM;Glioma detection;hybrid features;skull removal,Feature extraction;Tumors;Histograms;Brain;Standards;Cancer;Magnetic resonance imaging,biomedical MRI;brain;feature extraction;image classification;image enhancement;learning (artificial intelligence);medical image processing;neurophysiology;particle swarm optimisation;principal component analysis;support vector machines;tumours,hybrid features;malignant brain tumors;early detection;noninvasive automatic diagnosis system;image standardization;low-contrast standard brain images;outlier detection;intensity-based features;enhanced images;brain magnetic resonance imaging images;normal glioma;PSO-KSVM;machine learning methods;size normalization;background removal;skull removal;gray-level cooccurrence matrix;pyramid histogram;oriented gradient;modified completed local binary pattern;principal component analysis;Kernel support vector machine;particle swarm optimization;automatic detection;noninvasive system,,3,,35,,31-Jan-19,,,IEEE,IEEE Journals,yes,yes,,yes,Proposes a noninvasive automatic diagnosis system for gliomas based on the machine learning methods
A Novel Approach to Improving Brain Image Classification Using Mutual Information-Accelerated Singular Value Decomposition,Z. A. Al-Saffar; T. Yildirim,"Department of Biomedical Engineering, Al-Khwarizmi College of Engineering, University of Baghdad, Baghdad, Iraq; Department of Electronics and Communications Engineering, Yildiz Technical University, Istanbul, Turkey",IEEE Access,20-Mar-20,2020,8,,52575,52587,"Brain image classification is one of the most useful and widely needed processes in the medical system, and it is a highly challenging field. This paper presents a new method for selecting a significant subset of features as the input to the classifier, called mutual information-accelerated singular value decomposition (MI-ASVD). This novel algorithm is exploited to design an intelligent system for classifying MRI brain images into three classes: healthy, high-grade glioma, and low-grade glioma. The proposed system has six stages: pre-processing, clustering, tumour localization, feature extraction, MI-ASVD and classification. First, the MR images are smoothed by using enhancement techniques such as Gaussian kernel filters. Then, local difference in intensity-means (LDI-Means) clustering is employed to segment and detect suspicious regions. The grey-level run-length matrix (GLRLM), texture, and colour intensity features are used for tumour feature extraction. Later, a special method including a summation of feature selection and dimensionality reduction, MI-ASVD, is applied to select the most useful features for the classification process. Finally, the simplified residual neural network technique is implemented to classify the MR brain images. Using MI-ASVD provided accurate and more efficacious results in classification compared with the original feature space and with two other standard dimensionality reduction methods, principal component analysis (PCA) and singular value decomposition (SVD). It achieved a classification accuracy of 94.91%, which is better than the two state-of-the-art techniques as well as methods from similar published studies.",2169-3536,,10.1109/ACCESS.2020.2980728,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035475,Brain image classification;clustering;image processing;machine learning;mutual information;PCA;residual neural network (RNN);SVD,Feature extraction;Tumors;Principal component analysis;Brain;Magnetic resonance imaging;Dimensionality reduction;Biomedical imaging,biomedical MRI;brain;feature extraction;Gaussian processes;image classification;image segmentation;image texture;medical image processing;neural nets;principal component analysis;singular value decomposition;tumours,improving brain image classification;medical system;classifier;MI-ASVD;intelligent system;MRI brain images;healthy grade glioma;high-grade glioma;low-grade glioma;tumour localization;MR images;enhancement techniques;Gaussian kernel filters;local difference;intensity-means clustering;LDI-Means;grey-level run-length matrix;colour intensity features;tumour feature extraction;feature selection;classification process;simplified residual neural network technique;MR brain images;more efficacious results;standard dimensionality reduction methods;classification accuracy;mutual information-accelerated singular value decomposition,,,,56,CCBY,13-Mar-20,,,IEEE,IEEE Journals,yes,yes,,yes,"proposes of mutual information-accelerated singular value decomposition (MI-ASVD) to classify the MRI brain images into three classes: high-grade glioma, low-grade glioma and, healthy brain"
Hybrid Segmentation Method With Confidence Region Detection for Tumor Identification,K. Ejaz; M. S. M. Rahim; U. I. Bajwa; H. Chaudhry; A. Rehman; F. Ejaz,"School of Computing, University Teknologi Malaysia, Johor Bahru, Malaysia; School of Computing, University Teknologi Malaysia, Johor Bahru, Malaysia; Department of Information Technology, COMSATS University Lahore Campus Islamabad, Lahore, Pakistan; College of Engineering and Science, Victoria University, Footscray, VIC, Australia; Artificial Intelligence and Data Analytics (AIDA) Lab, CCIS, Prince Sultan University, Riyadh, Saudi Arabia; Department of RF Planning, Nokia, Al Khobar, Saudi Arabia",IEEE Access,04-Mar-21,2021,9,,35256,35278,"Segmentation methods can mutually exclude the location of the tumor. However, the challenge of complex location or incomplete identification is located in segmentation challenge dataset. Identificationof tumor location is difficult due to the variation of intensities in MRI image. Vairation of intensity extends up to edema. Confidence Region with Contour Detection identifies the variation of intensities and level set algorithm (Region Scale Fitting) is used to delineate among the region of inner and outer of the tumor. Automatic feature selection method is required due to data complexity. An improved Self Organization Feature Map. Method is required. Weighted SOM Map selects a deterministic feature. This feature is one higher trained accuracy feature. When this specific feature is combines with cluster therefore it is known as deterministic feature clustering. This method gives confidence element. Confidence Region with Contour detection is facing the issue due to extended variations of intensities. These intensities are segmented by hybrid SOM Pixel Labelling with Reduce Cluster Membership and Deterministic Feature Clustering. This hyhbrid method segments the complex tumor intensities. This method produces a potential cluster which is achieved through the hybrid of three unsupervised learning techniques. Hybrid cluster method segments the tumor region. Extended intensities are also segmented by this hybrid approach. Above methods are validated on MICCAI BraTs brain tumor dataset, this is a segmentation challenge dataset. Proposed hybrid algorithm is efficient and it's accuracy can be seen with testing parameters like Dice Overlap Index, Jaccard Tanimoto Coefficient Index, Mean Squared Error and Peak Signal to Noise Ratio. Dice OverlapIndex is 98%, Jaccard Index is 96 percent, Mean Squared Error is 0.06 and Peak Signal To Noise ratio is 18db. The performance of the suggested algorithm is compared to other state of the art.",2169-3536,,10.1109/ACCESS.2020.3016627,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166508,Self organization mapping (SOM);KMEAN;Fuzzy C Mean (FCM);features;feature extraction (FE);feature reduction (FR);feature selection (FS);MRI;contour detection;biggest blob area;intensity;hybrid segmentation;confidence region (CR);contour detection (CD),Tumors;Feature extraction;Image segmentation;Magnetic resonance imaging;Indexes;Image edge detection;Organizations,biomedical MRI;brain;feature selection;image segmentation;medical image processing;self-organising feature maps;tumours;unsupervised learning,MICCAI BraTs brain tumor dataset;hybrid segmentation method;tumor identification;tumor location;contour detection;level set algorithm;automatic feature selection method;self organization feature map;deterministic feature clustering;hybrid cluster method;confidence region detection;weighted SOM map;hybrid SOM pixel labelling;reduce cluster membership;unsupervised learning;MRI image,,,,30,CCBY,13-Aug-20,,,IEEE,IEEE Journals,yes,yes,,yes,Hybrid Segmentation Method detects tumour by producing a potential cluster achieved through a hybrid of three unsupervised learning techniques
Label-Free Detection of the Architectural Feature of Blood Vessels in Glioblastoma Based on Multiphoton Microscopy,S. Wang; X. Sun; Z. Chen; F. Huang; N. Fang; Y. Lin; X. Wang; J. Chen,"College of Mechanical Engineering and Automation, Fuzhou University, Fuzhou, China; College of Mechanical Engineering and Automation, Fuzhou University, Fuzhou, China; 5G Cloud Network Lab, China Unicom (Fujian) Industrial Internet Company, Ltd., Fuzhou, China; College of Mechanical Engineering and Automation, Fuzhou University, Fuzhou, China; Department of Ophthalmology and Optometry, Fujian Medical University, Fuzhou, China; Department of Neurosurgery, First Affiliated Hospital of Fujian Medical University, Fuzhou, China; Department of Pathology, First Affiliated Hospital of Fujian Medical University, Fuzhou, China; Key Laboratory of OptoElectronic Science and Technology for Medicine of Ministry of Education, Fujian Provincial Key Laboratory of Photonics Technology, Fujian Normal University, Fuzhou, China",IEEE Journal of Selected Topics in Quantum Electronics,02-Mar-21,2021,27,4,1,7,"Glioblastoma (GBM) is a highly angiogenesis malignant tumor with a significant heterogeneity of vascular morphology. The vascular patterns could be served as an indicator of vascular morphological complexity that associated with postoperative prognosis of patients with GBM. Here, multiphoton microscopy (MPM), based on second harmonic generation (SHG) and two-photon excited fluorescence (TPEF), is applied for detecting the architectural feature of blood vessels from ex vivo, unfixed, and unstained human GBM specimens. Combined with the image processing algorithms, the morphology, location, orientation, alignment, and density of vascular collagen are qualitatively and quantitatively visualized, revealing the presented method not only contribute to differentiate GBM from normal brain tissue, but also provide important indicators of different vascular patterns, which may serve as a reference to the prognosis more accurately. Therefore, these results can provide prognosis-related histopathological diagnosis of GBM, holding a translational potential to be used as a label-free, quick, and on-site imaging tool for clinicians to determine the extent of excision involving brain functional areas.",1558-4542,,10.1109/JSTQE.2021.3058175,National Natural Science Foundation of China; Natural Science Foundation of Fujian Province; Education and Scientific Research Foundation for Young Teachers in Fujian Province; Funds of Fujian Provincial Research Project; Reform of Undergraduate Education and Teaching; Special Funds of the Central Government Guiding Local Science and Technology Development; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9353209,Multiphoton microscopy (MPM);second harmonic generation (SHG);two-photon excited fluorescence (TPEF);blood vessel;glioblastoma,Biomedical imaging;Blood vessels;Imaging;Microscopy;Visualization;Morphology;Hospitals,biological tissues;biomedical optical imaging;blood vessels;brain;cancer;cellular biophysics;fluorescence;medical image processing;molecular biophysics;multiphoton processes;neurophysiology;optical harmonic generation;optical microscopy;patient diagnosis;proteins;tumours,prognosis-related histopathological diagnosis;different vascular patterns;normal brain tissue;differentiate GBM;vascular collagen;image processing algorithms;unstained human GBM specimens;two-photon excited fluorescence;postoperative prognosis;vascular morphological complexity;vascular morphology;significant heterogeneity;highly angiogenesis malignant tumor;multiphoton microscopy;glioblastoma;blood vessels;architectural feature;label-free detection,,,,35,IEEE,11-Feb-21,,,IEEE,IEEE Journals,yes,yes,,yes,Demonstrated label-free MPM blood vessel feature from normal brain and GBM specimens
Multi-Level Canonical Correlation Analysis for Standard-Dose PET Image Estimation,L. An; P. Zhang; E. Adeli; Y. Wang; G. Ma; F. Shi; D. S. Lalush; W. Lin; D. Shen,"Department of RadiologyBiomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of RadiologyBiomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of RadiologyBiomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; College of Computer Science, Sichuan University, Chengdu, China; Department of RadiologyBiomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of RadiologyBiomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Joint UNC-NCSU Department of Biomedical Engineering, North Carolina State University, Raleigh, NC, USA; Department of Radiology, Biomedical Research Imaging CenterMRI Laboratory, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of RadiologyBiomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",IEEE Transactions on Image Processing,01-Jun-16,2016,25,7,3303,3315,"Positron emission tomography (PET) images are widely used in many clinical applications, such as tumor detection and brain disorder diagnosis. To obtain PET images of diagnostic quality, a sufficient amount of radioactive tracer has to be injected into a living body, which will inevitably increase the risk of radiation exposure. On the other hand, if the tracer dose is considerably reduced, the quality of the resulting images would be significantly degraded. It is of great interest to estimate a standard-dose PET (S-PET) image from a low-dose one in order to reduce the risk of radiation exposure and preserve image quality. This may be achieved through mapping both S-PET and low-dose PET data into a common space and then performing patch-based sparse representation. However, a one-size-fits-all common space built from all training patches is unlikely to be optimal for each target S-PET patch, which limits the estimation accuracy. In this paper, we propose a data-driven multi-level canonical correlation analysis scheme to solve this problem. In particular, a subset of training data that is most useful in estimating a target S-PET patch is identified in each level, and then used in the next level to update common space and improve estimation. In addition, we also use multi-modal magnetic resonance images to help improve the estimation with complementary information. Validations on phantom and real human brain data sets show that our method effectively estimates S-PET images and well preserves critical clinical quantification measures, such as standard uptake value.",1941-0042,,10.1109/TIP.2016.2567072,National Institutes of Health; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468470,PET estimation;multi-level CCA;sparse representation;locality-constrained linear coding;multi-modal MRI;PET estimation;multi-level CCA;sparse representation;locality-constrained linear coding;multi-modal MRI,Positron emission tomography;Estimation;Dictionaries;Magnetic resonance imaging;Image reconstruction;Image quality,biological effects of radiation;biomedical MRI;brain;correlation theory;image representation;medical image processing;positron emission tomography;radioactive tracers;tumours,data-driven multilevel canonical correlation analysis;standard-dose PET image estimation;positron emission tomography image;tumor detection;brain disorder diagnosis;diagnostic quality;radioactive tracer;radiation exposure risk;image quality;patch-based sparse representation;training data subset;target S-PET patch;multimodal magnetic resonance image;human brain data set,,20,,45,,11-May-16,,,IEEE,IEEE Journals,yes,yes,,yes,Proposes a multilevel canonical correlation analysis for estimating standard-dose positron emission tomography image from a low-dose PET
Optimized Multistable Stochastic Resonance for the Enhancement of Pituitary Microadenoma in MRI,M. Singh; A. Verma; N. Sharma,"School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University) Varanasi, Varanasi, India; Department of Radio diagnosis and Imaging, Institute of Medical Sciences, Banaras Hindu University Varanasi, Varanasi, India; School of Biomedical Engineering, Indian Institute of Technology (Banaras Hindu University) Varanasi, Varanasi, India",IEEE Journal of Biomedical and Health Informatics,03-May-18,2018,22,3,862,873,"Magnetic resonance imaging (MRI) is the modality of choice as far as imaging diagnosis of pathologies in the pituitary gland is concerned. Furthermore, the advent of dynamic contrast enhanced (DCE) has enhanced the capability of this modality in detecting minute benign but endocrinologically significant tumors called microadenoma. These lesions are visible with difficulty and a low confidence level in routine MRI sequences, even after administration of intravenous gadolinium. Techniques to enhance the visualization of such foci would be an asset in improving the overall accuracy of DCE-MRI for detection of pituitary microadenomas. The present study proposes an algorithm for postprocessing DCE-MRI data using multistable stochastic resonance (MSSR) technique. Multiobjective ant lion optimization optimizes the contrast enhancement factor (CEF) and anisotropy of an image by varying the parameters associated with the dynamics of MSSR. The marked regions of interest (ROIs) are labeled as normal and microadenoma of pituitary obtained with increased level of accuracy and confidence using proposed algorithm. The increased difference between the mean intensity curves obtained using these ROIs validated the obtained subjective results. Furthermore, the proposed MSSR-based algorithm has been evaluated on standard T1 and T2 weighted BrainWeb dataset images and quantified in terms of CEF, peak signal to noise ratio (PSNR), structure similarity index measure (SSIM), and universal quality index (UQI). The obtained mean values of CEF 1.22, PSNR 27.68, SSIM 0.75, UQI 0.83 for twenty dataset images were highest among considered contrast enhancement algorithms for the comparison.",2168-2208,,10.1109/JBHI.2017.2715078,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947107,Microadenoma;multi-objective ant lion optimization;multi-stable stochastic resonance;pituitary gland,Magnetic resonance imaging;Stochastic resonance;Heuristic algorithms;Optimization;Image enhancement;Pituitary gland;Noise measurement,biomedical MRI;brain;image enhancement;medical image processing;stochastic processes;tumours,structure similarity index measure;optimized multistable stochastic resonance;pituitary microadenoma;magnetic resonance imaging;pituitary gland;dynamic contrast;endocrinologically significant tumors;intravenous gadolinium;DCE-MRI data;multistable stochastic resonance technique;multiobjective ant lion optimization;T2 weighted BrainWeb dataset images;contrast enhancement algorithms;MRI sequences;contrast enhancement factor;microadenoma;T1 weighted BrainWeb dataset images;universal quality index;peak-signal-to-noise-ratio,"Adenoma;Algorithms;Humans;Image Interpretation, Computer-Assisted;Magnetic Resonance Imaging;Pituitary Neoplasms;Stochastic Processes",2,,39,,13-Jun-17,,,IEEE,IEEE Journals,yes,yes,,yes,Uses MSSR-MOALO to enhance MRI images for diagnosis of microadenomas and lesions in the pituitary gland
Robust Cell Detection of Histopathological Brain Tumor Images Using Sparse Reconstruction and Adaptive Dictionary Selection,H. Su; F. Xing; L. Yang,"J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, FL, USA; Department of Electrical and Computer Engineering, University of Florida, FL, USA; J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, FL, USA",IEEE Transactions on Medical Imaging,30-May-16,2016,35,6,1575,1586,"Successful diagnostic and prognostic stratification, treatment outcome prediction, and therapy planning depend on reproducible and accurate pathology analysis. Computer aided diagnosis (CAD) is a useful tool to help doctors make better decisions in cancer diagnosis and treatment. Accurate cell detection is often an essential prerequisite for subsequent cellular analysis. The major challenge of robust brain tumor nuclei/cell detection is to handle significant variations in cell appearance and to split touching cells. In this paper, we present an automatic cell detection framework using sparse reconstruction and adaptive dictionary learning. The main contributions of our method are: 1) A sparse reconstruction based approach to split touching cells; 2) An adaptive dictionary learning method used to handle cell appearance variations. The proposed method has been extensively tested on a data set with more than 2000 cells extracted from 32 whole slide scanned images. The automatic cell detection results are compared with the manually annotated ground truth and other state-of-the-art cell detection algorithms. The proposed method achieves the best cell detection accuracy with a F1 score = 0.96.",1558-254X,,10.1109/TMI.2016.2520502,National Institutes of Health; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7389394,Cell detection;sparse reconstruction;trivial templates,Dictionaries;Testing;Image reconstruction;Shape;Robustness;Transforms;Tumors,brain;cellular biophysics;image reconstruction;medical image processing;tumours,robust cell detection;histopathological brain tumor images;sparse reconstruction;adaptive dictionary selection;automatic cell detection framework;adaptive dictionary learning;cell appearance variations;computer aided diagnosis;CAD;cancer diagnosis;cancer treatment;cellular analysis,"Algorithms;Brain;Brain Neoplasms;Histocytochemistry;Humans;Image Interpretation, Computer-Assisted;Machine Learning",23,,54,,21-Jan-16,,,IEEE,IEEE Journals,yes,yes,,yes,Presents an automatic cell detection algorithm by detetcting multiple cells on single image patch
Segmentation of Tumor and Edema Along With Healthy Tissues of Brain Using Wavelets and Neural Networks,A. Demirhan; M. Törü; İ. Güler,"Faculty of Technology, Electronics and Computer Technology, Ankara, Turkey; Department of Radiology, 29 Mayıs Hospital, Ankara, Turkey; Faculty of Technology, Electronics and Computer Technology, Ankara, Turkey",IEEE Journal of Biomedical and Health Informatics,23-Jul-15,2015,19,4,1451,1458,"Robust brain magnetic resonance (MR) segmentation algorithms are critical to analyze tissues and diagnose tumor and edema in a quantitative way. In this study, we present a new tissue segmentation algorithm that segments brain MR images into tumor, edema, white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF). The detection of the healthy tissues is performed simultaneously with the diseased tissues because examining the change caused by the spread of tumor and edema on healthy tissues is very important for treatment planning. We used T1, T2, and FLAIR MR images of 20 subjects suffering from glial tumor. We developed an algorithm for stripping the skull before the segmentation process. The segmentation is performed using self-organizing map (SOM) that is trained with unsupervised learning algorithm and fine-tuned with learning vector quantization (LVQ). Unlike other studies, we developed an algorithm for clustering the SOM instead of using an additional network. Input feature vector is constructed with the features obtained from stationary wavelet transform (SWT) coefficients. The results showed that average dice similarity indexes are 91% for WM, 87% for GM, 96% for CSF, 61% for tumor, and 77% for edema.",2168-2208,,10.1109/JBHI.2014.2360515,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6911956,Brain MR;image segmentation;learning vector quantization;self-organizing feature map;stationary wavelet transform;Brain magnetic resonance (MR);image segmentation;learning vector quantization (LVQ);self-organizing feature map;stationary wavelet transform (SWT),Image segmentation;Tumors;Feature extraction;Vectors;Training;Accuracy;Artificial neural networks,biomedical MRI;brain;image segmentation;medical image processing;neural nets;tumours;vector quantisation;wavelet transforms,neural networks;stationary wavelet transform coefficients;learning vector quantization;self-organizing map;segmentation process;skull;glial tumor;FLAIR MR images;cerebrospinal fluid;white matter;gray matter;tissue segmentation algorithm;tumor diagnosis;edema diagnosis;brain magnetic resonance segmentation algorithms,"Brain;Brain Neoplasms;Databases, Factual;Edema;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Neural Networks (Computer);Wavelet Analysis",82,,39,,26-Sep-14,,,IEEE,IEEE Journals,yes,yes,,yes,"Proposes a new tissue segmentation algorithm that segments brain MR images into tumor, edema, white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF)"
Towards Real-Time Computing of Intraoperative Hyperspectral Imaging for Brain Cancer Detection Using Multi-GPU Platforms,G. Florimbi; H. Fabelo; E. Torti; S. Ortega; M. Marrero-Martin; G. M. Callico; G. Danese; F. Leporati,"Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; Institute for Applied Microelectronics (IUMA), University of Las Palmas de Gran Canaria (ULPGC), Las Palmas de Gran Canaria, Spain; Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; Institute for Applied Microelectronics (IUMA), University of Las Palmas de Gran Canaria (ULPGC), Las Palmas de Gran Canaria, Spain; Institute for Applied Microelectronics (IUMA), University of Las Palmas de Gran Canaria (ULPGC), Las Palmas de Gran Canaria, Spain; Institute for Applied Microelectronics (IUMA), University of Las Palmas de Gran Canaria (ULPGC), Las Palmas de Gran Canaria, Spain; Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy",IEEE Access,14-Jan-20,2020,8,,8485,8501,"Several causes make brain cancer identification a challenging task for neurosurgeons during the surgical procedure. The surgeons' naked eye sometimes is not enough to accurately delineate the brain tumor location and extension due to its diffuse nature that infiltrates in the surrounding healthy tissue. For this reason, a support system that provides accurate cancer delimitation is essential in order to improve the surgery outcomes and hence the patient's quality of life. The brain cancer detection system developed as part of the “HypErspectraL Imaging Cancer Detection” (HELICoiD) European project meets this requirement exploiting a non-invasive technique suitable for medical diagnosis: the hyperspectral imaging (HSI). A crucial constraint that this system has to satisfy is providing a real-time response in order to not prolong the surgery. The large amount of data that characterizes the hyperspectral images, and the complex elaborations performed by the classification system make the High Performance Computing (HPC) systems essential to provide real-time processing. The most efficient implementation developed in this work, which exploits the Graphic Processing Unit (GPU) technology, is able to classify the biggest image of the database (worst case) in less than three seconds, largely satisfying the real-time constraint set to 1 minute for surgical procedures, becoming a potential solution to implement hyperspectral video processing in the near future.",2169-3536,,10.1109/ACCESS.2020.2963939,"Agencia Canaria de Investigación, Innovación y Sociedad de la Información; Spanish Government through PLATINO Project; European Commission; European Commission; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949497,Hyperspectral imaging;high performance computing;graphic processing unit;parallel processing;parallel architectures;image processing;biomedical engineering;medical diagnostic imaging;cancer detection;supervised classification;support vector machines;K-Nearest neighbors;principal component analysis;K-means;majority voting,Surgery;Real-time systems;Cancer detection;Tumors;Graphics processing units;Hyperspectral imaging;Cancer,biomedical optical imaging;brain;cancer;graphics processing units;image classification;medical image processing;surgery;tumours,real-time computing;intraoperative hyperspectral Imaging;multiGPU platforms;surgical procedure;brain tumor location;brain cancer detection system;HypErspectraL Imaging Cancer Detection European project;noninvasive technique suitable;real-time response;hyperspectral images;classification system;high performance computing systems;graphic processing unit technology;hyperspectral video processing;cancer delimitation,,3,,42,CCBY,03-Jan-20,,,IEEE,IEEE Journals,yes,yes,,yes,Uses multi-GPU platforms for real-time detection by acquiring an hyperspecstral image of the brain�
Visualization of White Matter Fiber Tracts of Brain Tissue Sections With Wide-Field Imaging Mueller Polarimetry,P. Schucht; H. R. Lee; H. M. Mezouar; E. Hewer; A. Raabe; M. Murek; I. Zubak; J. Goldberg; E. Kövari; A. Pierangelo; T. Novikova,"Department of Neurosurgery, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; LPICM, CNRS, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; LPICM, CNRS, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; Department of Pathology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Department of Neurosurgery, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Department of Neurosurgery, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Department of Neurosurgery, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Department of Neurosurgery, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Department of Mental Health and Psychiatry, University Hospitals of Geneva, Geneva, Switzerland; LPICM, CNRS, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; LPICM, CNRS, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France",IEEE Transactions on Medical Imaging,30-Nov-20,2020,39,12,4376,4382,"Identification of white matter fiber tracts of the brain is crucial for delineating the tumor border during neurosurgery. A custom-built Mueller polarimeter was used in reflection configuration for the wide-field imaging of thick sections of fixed human brain and fresh calf brain. The maps of the azimuth of the fast optical axis of linear birefringent medium reconstructed from the experimental Mueller matrix images of the specimen by applying a non-linear data compression algorithm showed a strong correlation with the silver-stained sample histology image, which is the gold standard for ex-vivo brain fiber tract visualization. The polarimetric maps of fresh calf brain tissue demonstrated the same trends in the depolarization, the scalar retardance and the azimuth of the fast optical axis as seen in fixed human brain tissue. Thus, label-free imaging Mueller polarimetry shows promise as an efficient intra-operative modality for the visualization of healthy brain white matter fiber tracts, which could improve the accuracy of tumor border detection and, ultimately, patient outcomes.",1558-254X,,10.1109/ACCESS.2020.3035345,"Ph.D. Fellowship from the Doctoral School Interfaces, École Polytechnique, France; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173792,Brain imaging;Mueller polarimetry;optical anisotropy;scattering;white matter fiber tracts visualization,Tumors;Brain;White matter;Optical imaging;Optical reflection;Optical variables measurement;Optical fibers,biomedical optical imaging;birefringence;brain;data compression;light polarisation;medical image processing;neurophysiology;polarimetry;tumours,fast optical axis;linear birefringent medium;Mueller matrix images;nonlinear data compression algorithm;silver-stained sample histology image;fresh calf brain tissue;fixed human brain tissue;label-free imaging;tumor border detection;brain white matter fiber;Mueller polarimetry;ex vivo brain fiber tract visualization;neurosurgery,,1,,52,IEEE,21-Aug-20,,,IEEE,IEEE Journals,yes,yes,,yes,Uses non-invasive and non-contact optic technique called Mueller polarimetry to detect the boundary between the white matter of the tumour and the healthy brain�
A New Multi-Atlas Registration Framework for Multimodal Pathological Images Using Conventional Monomodal Normal Atlases,Z. Tang; P. -T. Yap; D. Shen,"Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",IEEE Transactions on Image Processing,31-Jan-19,2019,28,5,2293,2304,"Using multi-atlas registration (MAR), information carried by atlases can be transferred onto a new input image for the tasks of region-of-interest (ROI) segmentation, anatomical landmark detection, and so on. Conventional atlases used in MAR methods are monomodal and contain only normal anatomical structures. Therefore, the majority of MAR methods cannot handle input multimodal pathological images, which are often collected in routine image-based diagnosis. This is because registering monomodal atlases with normal appearances to multimodal pathological images involves two major problems: 1) missing imaging modalities in the monomodal atlases and 2) influence from pathological regions. In this paper, we propose a new MAR framework to tackle these problems. In this framework, deep learning-based image synthesizers are applied for synthesizing multimodal normal atlases from conventional monomodal normal atlases. To reduce the influence from pathological regions, we further propose a multimodal low-rank approach to recover multimodal normal-looking images from multimodal pathological images. Finally, the multimodal normal atlases can be registered to the recovered multimodal images in a multi-channel way. We evaluate our MAR framework via brain ROI segmentation of multimodal tumor brain images. Due to the utilization of multimodal information and the reduced influence from pathological regions, experimental results show that registration based on our method is more accurate and robust, leading to significantly improved brain ROI segmentation compared with the state-of-the-art methods.",1941-0042,,10.1109/TIP.2018.2884563,National Institutes of Health; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579568,Image registration;multimodal image;pathological brain image;image synthesis;low-rank image recovery,Brain;Tumors;Pathology;Synthesizers;Gallium nitride;Image segmentation;Measurement,biomedical MRI;brain;image registration;image segmentation;learning (artificial intelligence);medical image processing;tumours,multimodal information;multimodal tumor brain images;recovered multimodal images;multimodal normal atlases;deep learning-based image synthesizers;MAR framework;pathological regions;normal appearances;monomodal atlases;routine image-based diagnosis;input multimodal pathological images;normal anatomical structures;MAR methods;conventional atlases;region-of-interest segmentation;input image;conventional monomodal normal atlases;new multiatlas registration framework,,1,,42,,16-Dec-18,,,IEEE,IEEE Journals,yes,yes,Does not answer the research question and fails to give empirical evidence as the paper discusses framework for input multimodal pathological images,no,
Deep Longitudinal Feature Representations for Detection of Postradiotherapy Brain Injury at Presymptomatic Stage,L. Zhong; X. Zhang; Y. Xi; Z. Lian; Q. Feng; W. Chen; S. Zhang; W. Yang,"Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Department of Radiology, Guangdong Provincial People’s Hospital, Guangdong Academy of Medical Sciences, Guangzhou, China; Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Department of Radiology, The First Affiliated Hospital of Jinan University, Guangzhou, China; Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China",IEEE Access,19-Oct-20,2020,8,,184710,184721,"Temporal lobe injury (TLI), a form of nervous system damage in the brain, is a major neurological complication after radiation therapy (RT). TLI must be highly valued because of the irreversible brain injury. This article aims to develop a predictive pipeline, called deep longitudinal feature representations (DLFR), to detect TLI at the presymptomatic stage accurately via the learning of effective deep longitudinal feature representations. DLFR characterizes high-level information and developmental changes within and across subjects The DLFR consists of four components: (i) extraction of deep features from a pretrained ResNet50 model; (ii) compression of learned highly representative features by the global max pooling; (iii) fusion of deep longitudinal features for the fully use of all follow-up data; (iv) random forest-based prediction of the diagnostic status. In total, 244 nasopharyngeal carcinoma patients before and after RT with a follow-up period of 0 ~ 9 years were included for analysis. All patients were divided into four different latency groups, and the current latency was used for training to predict the diagnostic status of the next latency. The AUCs of the predicted three different latency groups using DLFR were 0.64 ± 0.11, 0.76 ± 0.10, and 0.88 ± 0.05, while those of radiomics features were 0.56 ± 0.06, 0.63 ± 0.03, and 0.53 ± 0.04, and those of histogram of oriented gradients features were 0.60 ± 0.09, 0.52 ± 0.03, and 0.58 ± 0.06. Most importantly, the AUCs of the predicted three different latency groups for white matter regions were 0.66 ± 0.10, 0.80 ± 0.09, and 0.78 ± 0.09. Our proposed method can dynamically detect TLI at the presymptomatic stage, which can enable the administration of preventive neurological intervention.",2169-3536,,10.1109/ACCESS.2020.3030060,National Natural Science Foundation of China; Guangdong Provincial Key Laboratory of Medical Image Processing; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9220136,Temporal lobe injury;nasopharyngeal carcinoma;deep longitudinal features;white matter,Feature extraction;Radiomics;Medical diagnostic imaging;Data mining;Temporal lobe;Medical diagnosis,biomedical MRI;brain;cancer;feature extraction;injuries;learning (artificial intelligence);medical image processing;neurophysiology;radiation therapy,radiomics features;presymptomatic stage;postradiotherapy brain injury;temporal lobe injury;nervous system damage;neurological complication;radiation therapy;irreversible brain injury;predictive pipeline;high-level information;deep features;pretrained ResNet50 model;global max pooling;deep longitudinal features;random forest-based prediction;nasopharyngeal carcinoma patients;deep longitudinal feature representations,,,,59,CCBYNCND,12-Oct-20,,,IEEE,IEEE Journals,yes,yes,Does not answer the research question directly as it discusses about feature representation to detect an injury in nervous system in the brain ,no,
High-Resolution Encoder-Decoder Networks for Low-Contrast Medical Image Segmentation,S. Zhou; D. Nie; E. Adeli; J. Yin; J. Lian; D. Shen,"School of Computer, National University of Defense Technology, Changsha, China; Department of Radiology, University of North Carolina, Chapel Hill, NC, USA; Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA, USA; School of Cyberspace Science, Dongguan University of Technology, Guangdong, China; Department of Radiation Oncology, University of North Carolina, Chapel Hill, NC, USA; Department of Radiology, University of North Carolina, Chapel Hill, NC, USA",IEEE Transactions on Image Processing,24-Sep-19,2020,29,,461,475,"Automatic image segmentation is an essential step for many medical image analysis applications, include computer-aided radiation therapy, disease diagnosis, and treatment effect evaluation. One of the major challenges for this task is the blurry nature of medical images (e.g., CT, MR, and microscopic images), which can often result in low-contrast and vanishing boundaries. With the recent advances in convolutional neural networks, vast improvements have been made for image segmentation, mainly based on the skip-connection-linked encoder-decoder deep architectures. However, in many applications (with adjacent targets in blurry images), these models often fail to accurately locate complex boundaries and properly segment tiny isolated parts. In this paper, we aim to provide a method for blurry medical image segmentation and argue that skip connections are not enough to help accurately locate indistinct boundaries. Accordingly, we propose a novel high-resolution multi-scale encoder-decoder network (HMEDN), in which multi-scale dense connections are introduced for the encoder-decoder structure to finely exploit comprehensive semantic information. Besides skip connections, extra deeply supervised high-resolution pathways (comprised of densely connected dilated convolutions) are integrated to collect high-resolution semantic information for accurate boundary localization. These pathways are paired with a difficulty-guided cross-entropy loss function and a contour regression task to enhance the quality of boundary detection. The extensive experiments on a pelvic CT image dataset, a multi-modal brain tumor dataset, and a cell segmentation dataset show the effectiveness of our method for 2D/3D semantic segmentation and 2D instance segmentation, respectively. Our experimental results also show that besides increasing the network complexity, raising the resolution of semantic feature maps can largely affect the overall model performance. For different tasks, finding a balance between these two factors can further improve the performance of the corresponding network.",1941-0042,,10.1109/TIP.2019.2919937,National Key R&D Program of China; National Natural Science Foundation of China; National Institutes of Health; NIH; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741187,Image segmentation;low-contrast image;high-resolution pathway,Image segmentation;Semantics;Task analysis;Computed tomography;Shape;Medical diagnostic imaging,brain;computerised tomography;convolutional neural nets;diseases;entropy;feature extraction;image coding;image resolution;image segmentation;medical image processing;regression analysis;tumours,encoder-decoder structure;boundary localization;high-resolution multiscale encoder-decoder network;skip-connection-linked encoder-decoder deep architectures;disease diagnosis;difficulty-guided cross-entropy loss function;contour regression task;2D-3D semantic segmentation;semantic feature maps;computed tomography;pelvic CT image dataset;boundary detection;high-resolution semantic information;densely connected dilated convolutions;high-resolution pathways;multiscale dense connections;blurry medical image segmentation;complex boundaries;blurry images;convolutional neural networks;microscopic images;blurry nature;treatment effect evaluation;computer-aided radiation therapy;medical image analysis applications;automatic image segmentation;low-contrast medical image segmentation;network complexity;2D instance segmentation;cell segmentation dataset;multimodal brain tumor dataset,,9,,55,,19-Jun-19,,,IEEE,IEEE Journals,yes,yes,"Fails to asnwer the research question, the paper is based on any medical image with low contrast",no,
Human Lesion Detection Method Based on Image Information and Brain Signal,G. Li; D. Jiang; Y. Zhou; G. Jiang; J. Kong; G. Manogaran,"Key Laboratory of Metallurgical Equipment and Control Technology, Ministry of Education, Wuhan University of Science and Technology, Wuhan, China; Research Center of Biologic Manipulator and Intelligent Measurement and Control, Wuhan University of Science and Technology, Wuhan, China; Medical School, Wuhan University of Science and Technology, Wuhan, China; Research Center of Biologic Manipulator and Intelligent Measurement and Control, Wuhan University of Science and Technology, Wuhan, China; Key Laboratory of Metallurgical Equipment and Control Technology, Ministry of Education, Wuhan University of Science and Technology, Wuhan, China; VIT, University of California at Davis, Davis, CA, USA",IEEE Access,03-Feb-19,2019,7,,11533,11542,"The brain is the largest and most complex structure in the central nervous system. It dominates all activities in the body, and the lesions in the human body are also reflected in the brain signal. In this paper, the image method is used to assist the brain signal to detect the human lesion. Due to the particularity of medical images, there is no common segmentation method for any medical image, and there is no objective standard to judge whether the segmentation is effective. Medical image segmentation technology is still a bottleneck restricting the development and the application of other related technologies in medical image processing. Based on the above reasons, this paper proposes an improved region growing algorithm based on the fuzzy theory and region growing algorithm. The algorithm is used to segment the medical images of the liver and chest X-ray of different human organs. The improved algorithm uses a threshold segmentation algorithm to assist in the automatic selection of seed points and improves the region growing rules, then morphological post-processing is used to improve the segmentation effect. The experimental results show that the improved region growing algorithm has better segmentation effect under two different organs, which proves that the algorithm has certain applicability, and its accuracy and segmentation quality are better than the traditional region growing algorithm. This algorithm combines the advantages of the threshold method and traditional region growing method. It is feasible in algorithm and has certain application value.",2169-3536,,10.1109/ACCESS.2019.2891749,National Natural Science Foundation of China; Wuhan University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606912,Medical image segmentation;improved region growing algorithm;applicability method;brain signal,Image segmentation;Liver;Medical diagnostic imaging;Clustering algorithms;Computed tomography;Cancer,brain;fuzzy set theory;image segmentation;liver;medical image processing,brain signal;medical image segmentation technology;medical image processing;threshold segmentation algorithm;threshold method;human lesion detection method;image information;central nervous system;human organs;region growing algorithm;region growing method;fuzzy theory;morphological post-processing;liver,,4,,54,CCBY,10-Jan-19,,,IEEE,IEEE Journals,yes,yes,Does not answer the research question directly as the paper mainly focuses on lesions in the lung,no,
MAVEN: An Algorithm for Multi-Parametric Automated Segmentation of Brain Veins From Gradient Echo Acquisitions,S. Monti; S. Cocozza; P. Borrelli; S. Straub; M. E. Ladd; M. Salvatore; E. Tedeschi; G. Palma,"IRCCS SDN, Naples, Italy; Department of Advanced Biomedical Sciences, University Federico II, Naples, Italy; IRCCS SDN, Naples, Italy; Department of Medical Physics in Radiology, German Cancer Research Center, Heidelberg, Germany; Department of Medical Physics in Radiology, German Cancer Research Center, Heidelberg, Germany; IRCCS SDN, Naples, Italy; Department of Advanced Biomedical Sciences, University Federico II, Naples, Italy; National Research Council, Institute of Biostructure and Bioimaging, Naples, Italy",IEEE Transactions on Medical Imaging,01-May-17,2017,36,5,1054,1065,"Cerebral vein analysis provides a chance to study, from an unusual viewpoint, an entire class of brain diseases, including neurodegenerative disorders and traumatic brain injuries. Manual segmentation approaches can be used to assess vascular anatomy, but they are observer-dependent and time-consuming; therefore, automated approaches are desirable, as they also improve reproducibility. In this paper, a new, fully automated algorithm, based on structural, morphological, and relaxometric information, is proposed to segment the entire cerebral venous system from MR images. The algorithm for multi-parametric automated segmentation of brain VEiNs (MAVEN) is based on a combined investigation of multi-parametric information that allows for rejection of false positives and detection of thin vessels. The method is tested on gradient echo brain data sets acquired at 1.5, 3, and 7 T. It is compared to previous methods against manual segmentation, and its inter-scan reproducibility is assessed. The achieved accuracy and reproducibility are good, meaning that MAVEN outperforms previous methods on both quantitative and qualitative analyses. It is usable at all the field strengths explored, showing comparable accuracy scores, with no need for algorithm parameter adjustments, and thus, it is a promising candidate for the characterization of the venous tree topology.",1558-254X,,10.1109/TMI.2016.2645286,Italian Minister of Health; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859415,Brain veins;vesselness;segmentation;MRI,Veins;Image segmentation;Algorithm design and analysis;Diseases;Magnetic resonance imaging;Nonhomogeneous media;Manuals,biomedical MRI;blood vessels;brain;diseases;image segmentation;injuries;medical disorders;medical image processing;neurophysiology,MAVEN;multiparametric automated segmentation;brain veins;gradient echo acquisitions;cerebral vein analysis;brain diseases;neurodegenerative disorders;traumatic brain injuries;manual segmentation;observer-dependent vascular anatomy;fully automated algorithm;morphological information;structural information;relaxometric information;cerebral venous system;MR images;thin vessels;gradient echo brain data sets;quantitative analysis;qualitative analysis;comparable accuracy scores;algorithm parameter adjustments;venous tree topology,Algorithms;Brain;Cerebral Veins;Humans;Magnetic Resonance Imaging;Reproducibility of Results,8,,48,,20-Feb-17,,,IEEE,IEEE Journals,yes,yes,"Does not answer the research question, this paper is related to brain vein segmentation technique",no,
MRI Upsampling Using Feature-Based Nonlocal Means Approach,K. Jafari-Khouzani,"Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA",IEEE Transactions on Medical Imaging,29-Sep-14,2014,33,10,1969,1985,"In magnetic resonance imaging (MRI), spatial resolution is limited by several factors such as acquisition time, short physiological phenomena, and organ motion. The acquired image usually has higher resolution in two dimensions (the acquisition plane) in comparison with the third dimension, resulting in highly anisotropic voxel size. Interpolation of these low resolution (LR) images using standard techniques, such as linear or spline interpolation, results in distorted edges in the planes perpendicular to the acquisition plane. This poses limitation on conducting quantitative analyses of LR images, particularly on their voxel-wise analysis and registration. We have proposed a new non-local means feature-based technique that uses structural information of a high resolution (HR) image with a different contrast and interpolates the LR image. In this approach, the similarity between voxels is estimated using a feature vector that characterizes the laminar pattern of the brain structures, resulting in a more accurate similarity measure in comparison with conventional patch-based approach. This technique can be applied to LR images with both anisotropic and isotropic voxel sizes. Experimental results conducted on brain MRI scans of patients with brain tumors, multiple sclerosis, epilepsy, as well as schizophrenic patients and normal controls show that the proposed method is more accurate, requires fewer computations, and thus is significantly faster than a previous state-of-the-art patch-based technique. We also show how the proposed method may be used to upsample regions of interest drawn on LR images.",1558-254X,,10.1109/TMI.2014.2329271,NIH Clinical Center; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832581,Interpolation;magnetic resonance imaging (MRI);nonlocal means;super-resolution;upsampling,Interpolation;Magnetic resonance imaging;Image edge detection;Image reconstruction;Standards;Spatial resolution,biomedical MRI;brain;feature extraction;image resolution;medical disorders;medical image processing;neurophysiology;tumours,MRI upsampling;feature-based nonlocal means approach;magnetic resonance imaging;spatial resolution;image resolution;feature vector;brain structures;brain tumors;multiple sclerosis;epilepsy;schizophrenic patients,"Algorithms;Brain Neoplasms;Cerebral Cortex;Databases, Factual;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging",30,,25,,12-Jun-14,,,IEEE,IEEE Journals,yes,yes,"Fails to answer the research question; uses structural information of a high resolution image and interpolates with the low resolution image, by applying on MRI scans�",no,
Multi-Classification of Brain Tumor Images Using Deep Neural Network,H. H. Sultan; N. M. Salem; W. Al-Atabany,"Department of Biomedical Engineering, Faculty of Engineering, Helwan University, Cairo, Egypt; Department of Biomedical Engineering, Faculty of Engineering, Helwan University, Cairo, Egypt; Department of Biomedical Engineering, Faculty of Engineering, Helwan University, Cairo, Egypt",IEEE Access,05-Jun-19,2019,7,,69215,69225,"Brain tumor classification is a crucial task to evaluate the tumors and make a treatment decision according to their classes. There are many imaging techniques used to detect brain tumors. However, MRI is commonly used due to its superior image quality and the fact of relying on no ionizing radiation. Deep learning (DL) is a subfield of machine learning and recently showed a remarkable performance, especially in classification and segmentation problems. In this paper, a DL model based on a convolutional neural network is proposed to classify different brain tumor types using two publicly available datasets. The former one classifies tumors into (meningioma, glioma, and pituitary tumor). The other one differentiates between the three glioma grades (Grade II, Grade III, and Grade IV). The datasets include 233 and 73 patients with a total of 3064 and 516 images on T1-weighted contrast-enhanced images for the first and second datasets, respectively. The proposed network structure achieves a significant performance with the best overall accuracy of 96.13% and 98.7%, respectively, for the two studies. The results indicate the ability of the model for brain tumor multi-classification purposes.",2169-3536,,10.1109/ACCESS.2019.2919122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723045,Brain tumor;convolutional neural network;data augmentation;deep learning;MRI,Tumors;Feature extraction;Cancer;Task analysis;Magnetic resonance imaging;Convolutional neural networks;Training,biomedical MRI;brain;image classification;image segmentation;learning (artificial intelligence);medical image processing;neural nets;tumours,T1-weighted contrast-enhanced images;brain tumor multiclassification purposes;brain tumor images;deep neural network;brain tumor classification;imaging techniques;superior image quality;ionizing radiation;deep learning;machine learning;convolutional neural network;pituitary tumor;glioma grades;brain tumor type;meningioma;glioma;magnetic resonance imaging,,12,,41,,27-May-19,,,IEEE,IEEE Journals,yes,yes,"Does not answer the research question; classifies the different brain tumour into 3 types (meningioma, glioma and pituitary)",no,
Real-Time Transcranial Histotripsy Treatment Localization and Mapping Using Acoustic Cavitation Emission Feedback,J. R. Sukovich; J. J. Macoskey; J. E. Lundt; T. I. Gerhardson; T. L. Hall; Z. Xu,"Department of Biomedical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Biomedical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Biomedical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Biomedical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Biomedical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Biomedical Engineering, University of Michigan, Ann Arbor, MI, USA","IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control",25-May-20,2020,67,6,1178,1191,"Cavitation events generated during histotripsy therapy generate large acoustic cavitation emission (ACE) signals that can be detected through the skull. This article investigates the feasibility of using these ACE signals, acquired using the elements of a 500-kHz, 256-element hemispherical histotripsy transducer as receivers, to localize and map the cavitation activity in real time through the human skullcap during transcranial histotripsy therapy. The locations of the generated cavitation events predicted using the ACE feedback signals in this study were found to be accurate to within <; 1.5 mm of the centers of masses detected by optical imaging and found to lie to within the measured volumes of the generated cavitation events in ≳80% of cases. Localization results were observed to be biased in the prefocal direction of the histotripsy array and toward its transverse origin but were only weakly affected by focal steering location. The choice of skullcap and treatment pulse repetition frequency (PRF) were both observed to affect the accuracy of the localization results in the low PRF regime (1-10 Hz), but the localization accuracy was seen to stabilize at higher PRFs (≥10 Hz). Tests of the localization algorithm in vitro, for treatment delivered to a bovine brain sample mounted within the skullcap, revealed good agreement between the ACE feedback-generated treatment map and the morphological characteristics of the treated volume of the brain sample. Localization during experiments was achieved in real time for pulses delivered at rates up to 70 Hz, but benchmark tests indicate that the localization algorithm is scalable, indicating that higher rates are possible with more powerful hardware. The results of this article demonstrate the feasibility of using ACE feedback signals to localize and map transcranially generated cavitation events during histotripsy. Such capability has the potential to greatly simplify transcranial histotripsy treatments, as it may provide a non-MRI-based method for monitoring and localizing transcranial histotripsy treatments in real time.",1525-8955,,10.1109/TUFFC.2020.2967586,Focused Ultrasound Foundation; National Cancer Institute; National Institute of Neurological Disorders and Stroke (NINDS) of the National Institutes of Health; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8962001,Aberration correction;cavitation;histotripsy;noninvasive therapeutic ultrasound;transcranial therapy,Acoustics;Transducers;Ultrasonic imaging;Medical treatment;Monitoring;Real-time systems;Array signal processing,biological tissues;biomedical optical imaging;bone;brain;bubbles;cavitation;ultrasonic therapy,morphological characteristics;bovine brain;focal steering location;optical imaging;human skullcap;hemispherical histotripsy transducer;real-time transcranial histotripsy treatment localization;ACE feedback-generated treatment map;treatment pulse repetition frequency;ACE feedback signals;transcranial histotripsy therapy;acoustic cavitation emission signals;acoustic cavitation emission feedback;frequency 1.0 Hz to 10.0 Hz;frequency 500 kHz,"Algorithms;Animals;Brain;Cattle;Feedback;Image Processing, Computer-Assisted;Signal Processing, Computer-Assisted;Transducers;Ultrasonic Therapy;Ultrasonography",,,56,IEEE,17-Jan-20,,,IEEE,IEEE Journals,yes,yes,"Fails to answer the research question; demonstrates the use of ""ACE feedback to monitor and localize the transcranial cavitation events during histotripsy""�",no,
Reducing Acoustic Inhomogeneity Based on Speed of Sound Autofocus in Microwave Induced Thermoacoustic Tomography,S. Liu; Z. Zheng; X. Sun; Z. Zhao; Y. Zheng; H. Jiang; X. Zhu; Q. -H. Liu,"School of Electronic Science and EngineeringUniversity of Electronic Science and Technology of China; School of Electronic Science and EngineeringUniversity of Electronic Science and Technology of China; School of Electronic Science and EngineeringUniversity of Electronic Science and Technology of China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electrical and Electronic EngineeringNanyang Technological University; School of Electronic Science and EngineeringUniversity of Electronic Science and Technology of China; School of Electronic Science and EngineeringUniversity of Electronic Science and Technology of China; Department of Electrical and Computer EngineeringDuke University",IEEE Transactions on Biomedical Engineering,16-Jul-20,2020,67,8,2206,2214,"Microwave induced thermoacoustic tomography is a newly developing non-invasive and non-ionizing modality. In practical applications, such as breast tumor detection and brain imaging, the acoustic properties in the tissue to be detected are usually unknown and spatially non-uniform, which results in distortion and blurring of the buried targets. In this paper, a reconstruction method based on speed of sound (SoS) autofocus is proposed to reduce the effect of acoustic inhomogeneity in different soft tissues. According to this method, the number of tissue types, which are referred to as clusters in this work, can be automatically determined by a decision graph. To distinguish the boundaries of different tissues, a Gaussian Mixture Model (GMM) is fitted to the obtained image data for soft clustering instead of traditional hard clustering. Through fixing the tissue centers which are characterized by corresponding data density peaks as the means of Gaussian parameters rather than choosing them randomly, adaptive and robust reconstruction performance can be guaranteed. After performing an iterative GMM optimization, the SoS autofocus is achieved. Image reconstructed by using the updated SoS distribution is with higher accuracy than that with homogeneous assumption. Compared with the existing similar methods, the proposed method strategy obviates the need of extra experiment costs, and possesses good robustness with respect to hard assignment model errors when the medium is relatively complex. Realistic breast model and brain model simulations combined with experiments of agar phantom and pig's brain are provided to demonstrate the effectiveness of the proposed method.",1558-2531,,10.1109/TBME.2019.2957535,National Natural Science Foundation of China; China Scholarship Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922721,Microwave induced thermoacoustic tomography (MITAT);acoustic inhomogeneity;Gaussian Mixture Model;iterative optimization method,Image reconstruction;Acoustics;Gaussian mixture model;Nonhomogeneous media;Microwave imaging;Microwave theory and techniques,acoustic tomography;bioacoustics;biological organs;biomedical ultrasonics;brain;Gaussian processes;image reconstruction;iterative methods;medical image processing;microwave imaging;thermoacoustics;tumours,iterative GMM optimization;agar phantom;acoustic inhomogeneity;sound autofocus;microwave induced thermoacoustic tomography;breast tumor detection;brain imaging;soft tissues;Gaussian mixture model;image data;hard clustering;image reconstruction;realistic breast model,,,,38,IEEE,04-Dec-19,,,IEEE,IEEE Journals,yes,yes,Does not answer the research question; proposes a reconstruction method of distorted and blurred images of soft tissues in thermoacoustic tomography,no,
Registration of Pre- and Postresection Ultrasound Volumes With Noncorresponding Regions in Neurosurgery,H. Zhou; H. Rivaz,"Department of Electrical and Computer Engineering and the PERFORM Center, Concordia University, Montréal, QC, Canada; Department of Electrical and Computer Engineering and the PERFORM Center, Concordia University, Montréal, QC, Canada",IEEE Journal of Biomedical and Health Informatics,20-May-17,2016,20,5,1240,1249,"Brain tissue deforms significantly after opening the dura and during tumor resection, invalidating preoperative imaging data. Ultrasound is a popular imaging modality for providing the neurosurgeon with real-time updated images of brain tissue. Interpretation of postresection ultrasound images is difficult due to large brain shift and tissue resection. Furthermore, several factors degrade the quality of postresection ultrasound images such as the strong reflection of waves at the interface of saline water and brain tissue in resection cavities, air bubbles, and the application of blood-clotting agents around the edges of resection. Image registration allows the comparison of postresection ultrasound images with higher quality preresection images, assists in interpretation of postresection images and may help identify residual tumor, and, as such, is of significant clinical importance. In this paper, we propose a nonrigid symmetric registration (NSR) framework for accurate alignment of pre- and postresection volumetric ultrasound images in near real time. We first formulate registration as minimization of a regularized cost function and analytically derive its derivative to efficiently optimize the cost function. An outlier detection algorithm is proposed and utilized in this framework to identify noncorresponding regions (outliers) and therefore improve the robustness and accuracy of registration. We use an efficient second-order minimization method for fast and robust optimization. Furthermore, we exploit a symmetric and inverse-consistent method to generate realistic deformation fields. The results show that NSR significantly improves the quality of the alignment between pre- and postresection ultrasound images.",2168-2208,,10.1109/JBHI.2016.2554122,Natural Science and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452552,Efficient second-order minimization (ESM);image registration;neurosurgery;outlier detection;ultrasound imaging,Ultrasonic imaging;Tumors;Neurosurgery;Measurement;Imaging;Three-dimensional displays;Informatics,biomedical ultrasonics;image registration;medical image processing;minimisation;neurophysiology;surgery,ultrasound imaging;image registration;nonrigid symmetric registration;preresection volumetric ultrasound images;postresection volumetric ultrasound images;outlier detection algorithm;second-order minimization method;symmetric inverse-consistent method;neurosurgery,"Algorithms;Brain;Brain Neoplasms;Humans;Imaging, Three-Dimensional;Neurosurgical Procedures;Ultrasonography",15,,33,,14-Apr-16,,,IEEE,IEEE Journals,yes,yes,Does not directly answer the research question; proposes a nonrigid symmetric registration framework to align the pre- and postresection ultrasound images,no,
Spatially-Resolved Hydraulic Conductivity Estimation Via Poroelastic Magnetic Resonance Elastography,A. J. Pattison; M. McGarry; J. B. Weaver; K. D. Paulsen,"Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA",IEEE Transactions on Medical Imaging,29-May-14,2014,33,6,1373,1380,"Poroelastic magnetic resonance elastography is an imaging technique that could recover mechanical and hydrodynamical material properties of in vivo tissue. To date, mechanical properties have been estimated while hydrodynamical parameters have been assumed homogeneous with literature-based values. Estimating spatially-varying hydraulic conductivity would likely improve model accuracy and provide new image information related to a tissue's interstitial fluid compartment. A poroelastic model was reformulated to recover hydraulic conductivity with more appropriate fluid-flow boundary conditions. Simulated and physical experiments were conducted to evaluate the accuracy and stability of the inversion algorithm. Simulations were accurate (property errors were <; 2%) even in the presence of Gaussian measurement noise up to 3%. The reformulated model significantly decreased variation in the shear modulus estimate (p≪0.001) and eliminated the homogeneity assumption and the need to assign hydraulic conductivity values from literature. Material property contrast was recovered experimentally in three different tofu phantoms and the accuracy was improved through soft-prior regularization. A frequency-dependence in hydraulic conductivity contrast was observed suggesting that fluid-solid interactions may be more prominent at low frequency. In vivo recovery of both structural and hydrodynamical characteristics of tissue could improve detection and diagnosis of neurological disorders such as hydrocephalus and brain tumors.",1558-254X,,10.1109/TMI.2014.2311456,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774871,Hydraulic conductivity;magnetic resonance (MR) elastography;poroelasticity;soft prior,Conductivity;Mathematical model;Noise;Equations;Phantoms;Material properties,biological tissues;biomechanics;biomedical MRI;elasticity;Gaussian noise;phantoms;shear modulus,spatially-resolved hydraulic conductivity estimation;poroelastic magnetic resonance elastography;mechanical properties;hydrodynamical material properties;in vivo tissue;Gaussian measurement noise;shear modulus;tofu phantoms;soft-prior regularization;fluid-solid interactions;neurological disorder diagnosis;hydrocephalus;brain tumors,"Algorithms;Biomechanical Phenomena;Elastic Modulus;Elasticity Imaging Techniques;Image Processing, Computer-Assisted;Models, Biological;Phantoms, Imaging",16,,36,,18-Mar-14,,,IEEE,IEEE Journals,yes,yes,Does not answer the research question; measures the hydraulic conductivity related to tissues,no,
Volumetric Image Registration From Invariant Keypoints,B. Rister; M. A. Horowitz; D. L. Rubin,"Department of Electrical Engineering and the Department of Radiology (Biomedical Informatics Research), Stanford University, Stanford, CA, USA; Department of Electrical Engineering and the Department of Radiology (Biomedical Informatics Research), Stanford University, Stanford, CA, USA; Department of Electrical Engineering and the Department of Radiology (Biomedical Informatics Research), Stanford University, Stanford, CA, USA",IEEE Transactions on Image Processing,25-Jul-17,2017,26,10,4900,4910,"We present a method for image registration based on 3D scale- and rotation-invariant keypoints. The method extends the scale invariant feature transform (SIFT) to arbitrary dimensions by making key modifications to orientation assignment and gradient histograms. Rotation invariance is proven mathematically. Additional modifications are made to extrema detection and keypoint matching based on the demands of image registration. Our experiments suggest that the choice of neighborhood in discrete extrema detection has a strong impact on image registration accuracy. In head MR images, the brain is registered to a labeled atlas with an average Dice coefficient of 92%, outperforming registration from mutual information as well as an existing 3D SIFT implementation. In abdominal CT images, the spine is registered with an average error of 4.82 mm. Furthermore, keypoints are matched with high precision in simulated head MR images exhibiting lesions from multiple sclerosis. These results were achieved using only affine transforms, and with no change in parameters across a wide variety of medical images. This paper is freely available as a cross-platform software library.",1941-0042,,10.1109/TIP.2017.2722689,"National Cancer Institute, National Institutes of Health; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967757,Computer vision;3D SIFT;medical image registration;computed tomography (CT);magnetic resonance imaging (MRI),Histograms;Three-dimensional displays;Biomedical imaging;Image registration;Computed tomography;Tensile stress;Head,affine transforms;biomedical MRI;computerised tomography;image registration;medical image processing,volumetric image registration;scale invariant feature transform;SIFT;rotation-invariant keypoints;3D scale-invariant keypoints;orientation assignment;gradient histograms;keypoint matching;discrete extrema detection;head MR images;abdominal CT images;affine transforms,,6,,29,,03-Jul-17,,,IEEE,IEEE Journals,yes,yes,Does not answer the research question; discusses method for image registration based on 3D scale and rotation-invariant keypoints,no,
A Novel Algorithm for Breast Lesion Detection Using Textons and Local Configuration Pattern Features With Ultrasound Imagery,U. R. Acharya; K. M. Meiburger; J. E. Wei Koh; E. J. Ciaccio; N. Arunkumar; M. Hoong See; N. A. Mohd Taib; A. Vijayananthan; K. Rahmat; F. Fadzli; S. S. Leong; C. Judy Westerhout; A. Chantre-Astaiza; G. Ramirez-Gonzalez,"Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Medicine, Columbia University, New York City, NY, USA; Department of Electronics and Instrumentation, SASTRA University, Thanjavur, India; Department of Surgery, University of Malaya, Kuala Lumpur, Malaysia; Department of Surgery, University of Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Imaging, University of Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Imaging, University of Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Imaging, University of Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Imaging, University of Malaya Medical Centre, Kuala Lumpur, Malaysia; Department of Biomedical Imaging, University of Malaya, Kuala Lumpur, Malaysia; Department of Accounting, Economic and Administrative Sciences, University of Cauca, Popayan, Colombia; Department of Electronic Engineering and Telecommunications, University of Cauca, Popayan, Colombia",IEEE Access,28-Feb-19,2019,7,,22829,22842,"Breast cancer is the most commonly occurring cancer in women worldwide. While mammography remains the gold standard in breast cancer screening, ultrasound is an important imaging modality for both screening and cancer diagnosis. This paper presents a novel method for the detection of breast lesions in ultrasound images using texton filter banks, local configuration pattern features, and classification, without employing any segmentation technique. The developed method was able to accurately detect and classify breast lesions and achieved an accuracy, sensitivity, specificity, and positive predictive value of 96.1%, 96.5%, 95.3%, and 97.9%, respectively. The paradigm that we describe may, therefore, be useful as an effective tool to detect breast nodules during screening and in whole breast imaging, enabling clinicians to focus on images where a lesion is already known to be present. The developed method may also serve as a component for automatic breast nodule detection, and, when found, for the subsequent classification between lesion type benign versus malignant.",2169-3536,,10.1109/ACCESS.2019.2898121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642878,Breast;ultrasound;image;texton;local configuration pattern;malignant;benign;classifier,Filter banks;Breast;Ultrasonic imaging;Cancer;Lesions;Feature extraction;Imaging,biological organs;biomedical ultrasonics;cancer;feature extraction;image classification;medical image processing,breast lesion detection;local configuration pattern features;ultrasound imagery;breast cancer screening;cancer diagnosis;ultrasound images;texton filter banks;breast imaging;automatic breast nodule detection;imaging modality,,3,,40,,15-Feb-19,,,IEEE,IEEE Journals,no,,,,
A Review on Traditional Machine Learning and Deep Learning Models for WBCs Classification in Blood Smear Images,S. Khan; M. Sajjad; T. Hussain; A. Ullah; A. S. Imran,"Department of Computer Science, Digital Image Processing Laboratory, Islamia College University Peshawar, Peshawar, Pakistan; Department of Computer Science, Digital Image Processing Laboratory, Islamia College University Peshawar, Peshawar, Pakistan; Department of Software, Intelligent Media Laboratory, Sejong University, Seoul, South Korea; Department of Software, Intelligent Media Laboratory, Sejong University, Seoul, South Korea; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway",IEEE Access,20-Jan-21,2021,9,,10657,10673,"In computer vision, traditional machine learning (TML) and deep learning (DL) methods have significantly contributed to the advancements of medical image analysis (MIA) by enhancing prediction accuracy, leading to appropriate planning and diagnosis. These methods substantially improved the diagnoses of automatic brain tumor and leukemia/blood cancer detection and can assist the hematologist and doctors by providing a second opinion. This review provides an in-depth analysis of available TML and DL techniques for MIA with a significant focus on leukocytes classification in blood smear images and other medical imaging domains, i.e., magnetic resonance imaging (MRI), CT images, X-ray, and ultrasounds. The proposed review's main impact is to find the most suitable TML and DL techniques in MIA, especially for leukocyte classification in blood smear images. The advanced DL techniques, particularly the evolving convolutional neural networks-based models in the MIA domain, are deeply investigated in this review article. The related literature study reveals that mainstream TML methods are vastly applied to microscopic blood smear images for white blood cells (WBC) analysis. They provide valuable information to medical specialists and help diagnose various hematic diseases such as AIDS and blood cancer (Leukaemia). Based on WBC related literature study and its extensive analysis presented in this study, we derive future research directions for scientists and practitioners working in the MIA domain.",2169-3536,,10.1109/ACCESS.2020.3048172,"ERCIM ‘Alain Benoussan’ Fellowship Programme; ColorLab at the Department of Computer Science, NTNU, Gjøvik; Contract; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311202,Blood smear images;CNN;deep learning;medical image analysis;traditional machine learning;WBCs classification,Blood;Medical diagnostic imaging;Microscopy;Medical services;Solid modeling;Feature extraction;Diseases,biomedical MRI;biomedical ultrasonics;blood;brain;cancer;cellular biophysics;computerised tomography;convolutional neural nets;image classification;image segmentation;learning (artificial intelligence);medical image processing;reviews;tumours,magnetic resonance imaging;CT images;leukocyte classification;MIA domain;mainstream TML methods;microscopic blood smear images;white blood cell analysis;deep learning models;medical image analysis;automatic brain tumor;leukocytes classification;medical imaging;convolutional neural networks-based models;WBC classification;leukemia-blood cancer detection;review,,,,134,CCBY,30-Dec-20,,,IEEE,IEEE Journals,no,,,,
Adaptive Gaussian Weighted Laplace Prior Regularization Enables Accurate Morphological Reconstruction in Fluorescence Molecular Tomography,H. Meng; K. Wang; Y. Gao; Y. Jin; X. Ma; J. Tian,"CAS Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, China; CAS Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, China; CAS Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, China; CAS Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, China; CAS Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, China; CAS Key Laboratory of Molecular Imaging, Institute of Automation, Beijing, China",IEEE Transactions on Medical Imaging,27-Nov-19,2019,38,12,2726,2734,"Fluorescence molecular tomography (FMT), as a powerful imaging technique in preclinical research, can offer the three-dimensional distribution of biomarkers by detecting the fluorescently labelled probe noninvasively. However, because of the light scattering effect and the ill-pose of inverse problem, it is challenging to develop an efficient reconstruction method, which can provide accurate location and morphology of the fluorescence distribution. In this research, we proposed a novel adaptive Gaussian weighted Laplace prior (AGWLP) regularization method, which assumed the variance of fluorescence intensity between any two voxels had a non-linear correlation with their Gaussian distance. It utilized an adaptive Gaussian kernel parameter strategy to achieve accurate morphological reconstructions in FMT. To evaluate the performance of the AGWLP method, we conducted numerical simulation and in vivo experiments. The results were compared with fast iterative shrinkage (FIS) thresholding method, split Bregman-resolved TV (SBRTV) regularization method, and Gaussian weighted Laplace prior (GWLP) regularization method. We validated in vivo imaging results against planar fluorescence images of frozen sections. The results demonstrated that the AGWLP method achieved superior performance in both location and shape recovery of fluorescence distribution. This enabled FMT more suitable and practical for in vivo visualization of biomarkers.",1558-254X,,10.1109/TMI.2019.2912222,Ministry of Science and Technology of the People's Republic of China; National Natural Science Foundation of China; Chinese Academy of Sciences; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695042,Fluorescence tomography;multi-modality fusion;brain,Fluorescence;Image reconstruction;Imaging;In vivo;Kernel;Probes;Tumors,biomedical optical imaging;fluorescence;Gaussian processes;image denoising;image reconstruction;inverse problems;iterative methods;medical image processing;optical tomography,accurate morphological reconstruction;fluorescence molecular tomography;FMT;powerful imaging technique;preclinical research;fluorescently labelled probe;light scattering effect;reconstruction method;morphology;fluorescence distribution;fluorescence intensity;Gaussian distance;adaptive Gaussian kernel parameter strategy;AGWLP method;fast iterative shrinkage thresholding method;Bregman-resolved TV regularization method;planar fluorescence images;in vivo imaging results;adaptive Gaussian weighted Laplace prior regularization method,"Algorithms;Animals;Brain;Imaging, Three-Dimensional;Male;Mice;Mice, Inbred BALB C;Normal Distribution;Phantoms, Imaging;Tomography, Optical",4,,38,OAPA,22-Apr-19,,,IEEE,IEEE Journals,yes,no,,,
Automatic Lung Segmentation With Juxta-Pleural Nodule Identification Using Active Contour Model and Bayesian Approach,H. Chung; H. Ko; S. J. Jeon; K. -H. Yoon; J. Lee,"Department of Biomedical Engineering, Wonkwang University College of Medicine, Iksan, South Korea; Department of Biomedical Engineering, Wonkwang University College of Medicine, Iksan, South Korea; Department of Radiology, Wonkwang University College of Medicine, Iksan, South Korea; Department of Radiology, Wonkwang University College of Medicine, Iksan, South Korea; Department of Biomedical Engineering, Wonkwang University College of Medicine, Iksan, South Korea",IEEE Journal of Translational Engineering in Health and Medicine,11-Jun-18,2018,6,,1,13,"Objective: chest computed tomography (CT) images and their quantitative analyses have become increasingly important for a variety of purposes, including lung parenchyma density analysis, airway analysis, diaphragm mechanics analysis, and nodule detection for cancer screening. Lung segmentation is an important prerequisite step for automatic image analysis. We propose a novel lung segmentation method to minimize the juxta-pleural nodule issue, a notorious challenge in the applications. Method: we initially used the Chan-Vese (CV) model for active lung contours and adopted a Bayesian approach based on the CV model results, which predicts the lung image based on the segmented lung contour in the previous frame image or neighboring upper frame image. Among the resultant juxta-pleural nodule candidates, false positives were eliminated through concave points detection and circle/ellipse Hough transform. Finally, the lung contour was modified by adding the final nodule candidates to the area of the CV model results. Results: to evaluate the proposed method, we collected chest CT digital imaging and communications in medicine images of 84 anonymous subjects, including 42 subjects with juxta-pleural nodules. There were 16873 images in total. Among the images, 314 included juxta-pleural nodules. Our method exhibited a disc similarity coefficient of 0.9809, modified hausdorff distance of 0.4806, sensitivity of 0.9785, specificity of 0.9981, accuracy of 0.9964, and juxta-pleural nodule detection rate of 96%. It outperformed existing methods, such as the CV model used alone, the normalized CV model, and the snake algorithm. Clinical impact: the high accuracy with the juxta-pleural nodule detection in the lung segmentation can be beneficial for any computer aided diagnosis system that uses lung segmentation as an initial step.",2168-2372,,10.1109/JTEHM.2018.2837901,"Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Science, ICT & Future Planning; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361032,Active contour;lung segmentation;chest CT images;computer aided diagnosis;juxta-pleural nodule,Lung;Image segmentation;Computed tomography;Bayes methods;Level set;Brain modeling;DICOM,Bayes methods;cancer;computerised tomography;feature extraction;Hough transforms;image classification;image segmentation;lung;medical image processing,modified hausdorff distance;computer aided diagnosis system;circle/ellipse Hough transform;concave points detection;collected chest CT digital imaging;clinical impact;normalized CV model;juxta-pleural nodule detection rate;medicine images;final nodule candidates;resultant juxta-pleural nodule candidates;previous frame image;segmented lung contour;lung image;CV model results;active lung contours;Chan-Vese model;juxta-pleural nodule issue;novel lung segmentation method;automatic image analysis;important prerequisite step;diaphragm mechanics analysis;airway analysis;lung parenchyma density analysis;chest computed tomography images;Bayesian approach;active contour model;juxta-pleural nodule identification;automatic lung segmentation,,8,,47,,18-May-18,,,IEEE,IEEE Journals,no,,,,
Combining Multiple Boundary Shapes in Deformable EIT a Potential Use in Breast Imaging,J. Hu; M. Soleimani,"Department of Electronic and Electrical Engineering, Engineering Tomography Laboratory, University of Bath, Claverton Down, U.K.; Department of Electronic and Electrical Engineering, Engineering Tomography Laboratory, University of Bath, Claverton Down, U.K.",IEEE Sensors Letters,09-Apr-20,2020,4,4,1,4,"A few emerging medical imaging methods are being developed for breast imaging. Electrical impedance tomography (EIT) is an excellent candidate for safe, low cost, and noninvasive breast cancer monitoring. Despite early promises, the EIT faces a few challenges for the breast imaging application. It is mainly due to its limited resolution and especially for the tumors in depth. However, unlike the other medical applications of EIT, such as brain and thorax, breast tissues are deformable. This article exploits the deformation of breast shape to enhance the EIT resolution and its depth detection. Exterior boundary of the breast can be used to create deformable EIT with multiple shapes to enhance the imaging resolution, turning a challenge to an opportunity. With deformation of the boundary shape, more independent measurements can be obtained, and hence, more information can be gained. This can increase the resolution of the reconstructed image and possible detection for smaller tumors in depth. This article demonstrates it by experimental verification in phantom test representing tumor size inclusion deep inside the breast by a few deformed shape phantoms. To evaluate the experimental results, 3-D printed phantoms are built in several different shapes. Quantitative image analysis shows that some of the deformed shapes are superior to a traditional circular cross section. Additionally, we proposed a combination of data from all shapes so that all this information can be used in one step reconstruction to achieve higher imaging accuracy.",2475-1472,,10.1109/LSENS.2020.2978289,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025058,Sensor systems;breast cancer diagnosis;deformed boundaries in electrical impedance tomography (EIT),Shape;Tomography;Image reconstruction;Breast cancer;Electrodes,cancer;computerised tomography;electric impedance imaging;image reconstruction;image resolution;mammography;medical image processing;tumours,exterior boundary;deformable EIT;multiple shapes;imaging resolution;boundary shape;reconstructed image;deformed shape phantoms;image analysis;deformed shapes;medical imaging methods;electrical impedance tomography;noninvasive breast cancer monitoring;breast imaging application;medical applications;breast tissues;EIT resolution,,,,16,IEEE,05-Mar-20,,,IEEE,IEEE Journals,no,,,,
"Development of Algorithms for Automated Detection of Cervical Pre-Cancers With a Low-Cost, Point-of-Care, Pocket Colposcope",M. N. Asiedu; A. Simhal; U. Chaudhary; J. L. Mueller; C. T. Lam; J. W. Schmitt; G. Venegas; G. Sapiro; N. Ramanujam,"Duke University, Durham, NC, USA; Duke University; Duke University; Duke University; Duke University; Duke Medical Center; La Liga Contra El Cancer; Duke University; Duke University",IEEE Transactions on Biomedical Engineering,17-Jul-19,2019,66,8,2306,2318,"Goal: In this paper, we propose methods for (1) automatic feature extraction and classification for acetic acid and Lugol's iodine cervigrams and (2) methods for combining features/diagnosis of different contrasts in cervigrams for improved performance. Methods: We developed algorithms to pre-process pathology-labeled cervigrams and extract simple but powerful color and textural-based features. The features were used to train a support vector machine model to classify cervigrams based on corresponding pathology for visual inspection with acetic acid, visual inspection with Lugol's iodine, and a combination of the two contrasts. Results: The proposed framework achieved a sensitivity, specificity, and accuracy of 81.3%, 78.6%, and 80.0%, respectively, when used to distinguish cervical intraepithelial neoplasia (CIN+) relative to normal and benign tissues. This is superior to the average values achieved by three expert physicians on the same data set for discriminating normal/benign cases from CIN+ (77% sensitivity, 51% specificity, and 63% accuracy). Conclusion: The results suggest that utilizing simple color- and textural-based features from visual inspection with acetic acid and visual inspection with Lugol's iodine images may provide unbiased automation of cervigrams. Significance: This would enable automated, expert-level diagnosis of cervical pre-cancer at the point of care.",1558-2531,,10.1109/TBME.2018.2887208,Allen Institute for Brain Sciences; National Geospatial-Intelligence Agency; Office of Naval Research; U.S. Army Research Office; National Science Foundation; U.S. National Geospatial Intelligence Agency; National Institute of Health Quick Trials; National Institute of Health Academic-Industrial Partnerships; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580569,Computer-aided detection and diagnosis;cervix;feature extraction;machine learning;colposcopy;image acquisition;segmentation;predictive models;global health,Handheld computers;Phase shift keying,biological tissues;biomedical optical imaging;cancer;feature extraction;gynaecology;image classification;image colour analysis;image texture;medical image processing;support vector machines,automatic feature extraction;pathology-labeled cervigram;point-of-care colposcope;low-cost colposcope;support vector machine model;textural-based features;Lugol's iodine cervigrams;pocket colposcope;automated detection;cervical pre-cancer;expert-level diagnosis;Lugol's iodine images;benign tissues;normal tissues;cervical intraepithelial neoplasia;acetic acid;visual inspection,"Algorithms;Cervix Uteri;Colposcopes;Early Detection of Cancer;Female;Humans;Image Interpretation, Computer-Assisted;Machine Learning;Point-of-Care Systems;Precancerous Conditions;Uterine Cervical Neoplasms",6,,59,,18-Dec-18,,,IEEE,IEEE Journals,no,,,,
Melanoma Lesion Detection and Segmentation Using YOLOv4-DarkNet and Active Contour,S. Albahli; N. Nida; A. Irtaza; M. H. Yousaf; M. T. Mahmood,"Department of Information Technology, College of Computer, Qassim University, Buraydah, Saudi Arabia; Department of Computer Science, Air University Islamabad, Aerospace and Aviation Campus, Kamra, Pakistan; Department of Computer Science, University of Engineering and Technology, Taxila, Pakistan; Department of Computer Science, University of Engineering and Technology, Taxila, Pakistan; School of Computer Science and Engineering, College of Future Convergence, Korea University of Technology and Education, Cheonan, South Korea",IEEE Access,09-Nov-20,2020,8,,198403,198414,"Melanoma is the skin cancer caused by the ultraviolet radiation from the Sun and has only 15-20% of survival rate. Late diagnosis of melanoma leads to the severe malignancy of disease, and metastasis expands to the other body organs i.e. liver, lungs and brain. The dermatologists analyze the pigmented lesions over the skin to discriminate melanoma from other skin diseases. However, the imprecise analysis results in the form of a series of biopsies and it complicates the treatment. Meanwhile, the process of melanoma detection can be expedited through computer vision methods by analyzing the dermoscopic images automatically. However, the visual similarity between the normal and infected skin regions, and artifacts like gel bubbles, hair and clinical marks indicate low accuracy rates for these approaches. To overcome these challenges, in this article, a melanoma detection and segmentation approach is presented that brings significant improvement in terms of accuracy against state-of-the-art approaches. As a first step, the artifacts like hairs, gel bubbles, and clinical marks are removed from the dermoscopic images by applying the morphological operations, and image regions are sharpen. Afterwards, for infected region detection, we used YOLOv4 object detector by tuning it for melanoma detection to discriminate the highly correlated infected and non-infected regions. Once the bounding boxes against the melanoma regions are obtained, the infected melanoma regions are extracted by applying the active contour segmentation approach. For performance evaluation, the proposed approach is evaluated on ISIC2018 and ISIC2016 datasets and results are compared against state-of-the-art melanoma detection, and segmentation techniques. Our proposed approach achieves average dice score as 1 and Jaccard coefficient as 0.989. The segmentation result validates the practical bearing of our method in development of clinical decision support system for melanoma diagnosis in contrast to state-of-the-art methods. The YOLOv4 detector is capable to detect multiple skin diseases of same patient and multiple diseases of various patients.",2169-3536,,10.1109/ACCESS.2020.3035345,"Deanship of Scientific Research, Qassim University for funding the publication of this project; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247186,Deep neural networks;skin cancer;skin lesion segmentation;active contour segmentation;CAD tool;melanoma localization;YOLOv4,Hair;Image segmentation;Melanoma;Skin;Lesions;Diseases;Active contours,biomedical optical imaging;brain;cancer;computer vision;decision support systems;diseases;feature extraction;image classification;image colour analysis;image segmentation;liver;lung;medical image processing;skin,skin cancer;YOLOv4-DarkNet;melanoma lesion detection;skin diseases;YOLOv4 detector;melanoma diagnosis;melanoma detection;active contour segmentation approach;infected melanoma regions;noninfected regions;YOLOv4 object detector;infected region detection;image regions;dermoscopic images;clinical marks;gel bubbles;infected skin regions,,,,34,CCBY,03-Nov-20,,,IEEE,IEEE Journals,no,,,,
"PET Parametric Imaging: Past, Present, and Future",G. Wang; A. Rahmim; R. N. Gunn,"Department of Radiology, University of California Davis Health, Sacramento, CA, USA; Departments of Radiology and Physics, University of British Columbia, Vancouver, Canada; Department of Brain Sciences, Imperial College London, London, U.K.",IEEE Transactions on Radiation and Plasma Medical Sciences,02-Nov-20,2020,4,6,663,675,"Positron emission tomography (PET) is actively used in a diverse range of applications in oncology, cardiology, and neurology. The use of PET in the clinical setting focuses on static (single time frame) imaging at a specific time-point post radiotracer injection and is typically considered as semi-quantitative; e.g., standardized uptake value (SUV) measures. In contrast, dynamic PET imaging requires increased acquisition times but has the advantage that it measures the full spatiotemporal distribution of a radiotracer and, in combination with tracer kinetic modeling, enables the generation of multiparametric images that more directly quantify underlying biological parameters of interest, such as blood flow, glucose metabolism, and receptor binding. Parametric images have the potential for improved detection and for more accurate and earlier therapeutic response assessment. Parametric imaging with dynamic PET has witnessed extensive research in the past four decades. In this article, we provide an overview of past and present activities and discuss emerging opportunities in the field of parametric imaging for the future.",2469-7303,,10.1109/TRPMS.2020.3025086,National Institutes of Health; Natural Sciences and Engineering Research Council of Canada Discovery; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201038,Dynamic imaging;image reconstruction;kinetic modeling;parametric imaging;positron emission tomography (PET),Positron emission tomography;Image reconstruction;Radiotracer;Biomedical imaging,cancer;medical image processing;neurophysiology;positron emission tomography;radioactive tracers;spatiotemporal phenomena;tumours,receptor binding;glucose metabolism;blood flow;positron emission tomography;PET parametric imaging;multiparametric images;dynamic PET imaging;standardized uptake value measurement;specific time-point post radiotracer injection;single time frame;static imaging,,,,150,IEEE,21-Sep-20,,,IEEE,IEEE Journals,yes,no,,,